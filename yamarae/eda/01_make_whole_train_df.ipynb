{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. EDA cate & preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### read json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../dataset/\"\n",
    "json_file = \"cate1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data=open(data_path + json_file).read()\n",
    "data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big cate cnt : 57\n",
      "middle cate cnt : 552\n",
      "small cate cnt : 3190\n",
      "detail cate cnt : 404\n"
     ]
    }
   ],
   "source": [
    "print(\"big cate cnt :\", str(len(data['b'])))\n",
    "print(\"middle cate cnt :\", str(len(data['m'])))\n",
    "print(\"small cate cnt :\", str(len(data['s'])))\n",
    "print(\"detail cate cnt :\", str(len(data['d'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read hdf5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = \"train.chunk.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_data = h5py.File(data_path + hdf5_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_key = list(hdf5_data.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_group_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bcateid',\n",
       " 'brand',\n",
       " 'dcateid',\n",
       " 'img_feat',\n",
       " 'maker',\n",
       " 'mcateid',\n",
       " 'model',\n",
       " 'pid',\n",
       " 'price',\n",
       " 'product',\n",
       " 'scateid',\n",
       " 'updttm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hdf5_data['train'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hd5f to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5, ..., 14, 24, 42], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_data['train']['bcateid'][0:idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['퍼즐라이프', '바보사랑', '크리비아', ..., '크로바패션', '', ''], dtype='<U65')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x.decode('utf-8') for x in hdf5_data['train']['brand'][0:idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16520, 20370,    -1, ..., 15940,    -1,    -1], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_data['train']['price'][0:idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make whole train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(hdf5_data, idx):\n",
    "    df = pd.DataFrame(\n",
    "        {'bcateid': hdf5_data['train']['bcateid'][0:idx],\n",
    "         'mcateid': hdf5_data['train']['mcateid'][0:idx],\n",
    "         'scateid': hdf5_data['train']['scateid'][0:idx],\n",
    "         'dcateid': hdf5_data['train']['dcateid'][0:idx],\n",
    "         'brand': np.array([x.decode('utf-8') for x in hdf5_data['train']['brand'][0:idx]]),\n",
    "         'maker': np.array([x.decode('utf-8') for x in hdf5_data['train']['maker'][0:idx]]),\n",
    "         'model': np.array([x.decode('utf-8') for x in hdf5_data['train']['model'][0:idx]]),\n",
    "         'product': np.array([x.decode('utf-8') for x in hdf5_data['train']['product'][0:idx]]),\n",
    "         'price': hdf5_data['train']['price'][0:idx],\n",
    "         'updttm': hdf5_data['train']['updttm'][0:idx],\n",
    "         'pid': hdf5_data['train']['pid'][0:idx]\n",
    "        })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/no-error/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "columns = ['bcateid', 'mcateid', 'scateid', 'dcateid', 'brand', 'maker', 'model',\n",
    "       'product', 'price', 'updttm', 'pid']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "for number in range(1,10):\n",
    "    hdf5_file = \"train.chunk.\" + \"0\" + str(number)\n",
    "    hdf5_data = h5py.File(data_path + hdf5_file, 'r')\n",
    "    chunk_df = make_df(hdf5_data, 1000000)\n",
    "    df = df.append(chunk_df)\n",
    "file_name = data_path + \"train_sample.csv\"\n",
    "df.to_csv(file_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
